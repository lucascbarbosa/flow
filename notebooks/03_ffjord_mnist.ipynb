{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 3: FFJORD em MNIST Completo\n",
        "\n",
        "Este notebook implementa FFJORD (Free-form Jacobian of Reversible Dynamics) para treinar em MNIST completo usando Hutchinson trace estimator.\n",
        "\n",
        "## Objetivos:\n",
        "1. Implementar FFJORD com Hutchinson trace estimator\n",
        "2. Treinar em MNIST completo (784 dimensões) com preprocessing adequado\n",
        "3. Avaliar log-likelihood e bits per dimension\n",
        "4. Gerar amostras e visualizar resultados\n",
        "5. Analisar trade-offs computacionais (NFEs, tempo de treinamento)\n",
        "6. Comparar com RealNVP baseline (opcional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('..')\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from src.models.ffjord import FFJORD\n",
        "from src.models.vector_field import VectorFieldMNIST\n",
        "from src.utils.datasets import MNISTComplete, get_dataloader\n",
        "from src.utils.training import train_ffjord, train_realnvp\n",
        "from zuko.flows import RealNVP\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Directories for saving figures and checkpoints\n",
        "FIGURES_DIR = '../results/figures'\n",
        "CHECKPOINTS_DIR = '../results/checkpoints'\n",
        "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
        "\n",
        "# Dataset name for file naming\n",
        "DATASET_NAME = 'mnist'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Carregar Dataset MNIST com Preprocessing\n",
        "\n",
        "MNIST requer preprocessing adequado para flows:\n",
        "- **Dequantization**: Adiciona ruído uniforme para tornar dados contínuos\n",
        "- **Logit transform**: Transforma [0, 1] para R usando logit(x) = log(x / (1-x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Carregando MNIST completo...\n",
            "Training samples: 60000\n",
            "Test samples: 10000\n",
            "Feature dimension: 784\n",
            "Figure saved to: ../results/figures/03_mnist_ffjord_samples.png\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Carregar MNIST completo com preprocessing\n",
        "print(\"Carregando MNIST completo...\")\n",
        "train_dataset = MNISTComplete(train=True)\n",
        "test_dataset = MNISTComplete(train=False)\n",
        "\n",
        "train_loader = get_dataloader(train_dataset, batch_size=256, shuffle=True)\n",
        "test_loader = get_dataloader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "print(f\"Feature dimension: {train_dataset[0].shape[0]}\")\n",
        "\n",
        "# Visualizar algumas amostras (após preprocessing)\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "for i in range(10):\n",
        "    row, col = i // 5, i % 5\n",
        "    sample = train_dataset[i].cpu().numpy()\n",
        "    # Inverter logit transform para visualização\n",
        "    # x = sigmoid(sample) = 1 / (1 + exp(-sample))\n",
        "    sample_vis = 1 / (1 + np.exp(-sample))\n",
        "    sample_vis = sample_vis.reshape(28, 28)\n",
        "    axes[row, col].imshow(sample_vis, cmap='gray')\n",
        "    axes[row, col].axis('off')\n",
        "plt.suptitle('MNIST Samples (after dequantization + logit)', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIGURES_DIR, f'03_{DATASET_NAME}_ffjord_samples.png'), dpi=300, bbox_inches='tight')\n",
        "print(f\"Figure saved to: {os.path.join(FIGURES_DIR, f'03_{DATASET_NAME}_ffjord_samples.png')}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Criar e Treinar FFJORD\n",
        "\n",
        "FFJORD usa Hutchinson trace estimator para escalar a dimensões altas:\n",
        "- **Trace exato**: O(d²) - inviável para 784 dim\n",
        "- **Hutchinson**: O(d) - escalável!\n",
        "\n",
        "Hiperparâmetros recomendados (do PDF):\n",
        "- Learning rate: 1e-4\n",
        "- Batch size: 128-256\n",
        "- Regularização KE: λ_KE = 0.01\n",
        "- Warm-up: 5 epochs\n",
        "- Epochs: 50-100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Treinando FFJORD em MNIST completo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/50:   0%|          | 0/235 [00:22<?, ?it/s]\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 5.91 GiB of which 314.25 MiB is free. Including non-PyTorch memory, this process has 5.56 GiB memory in use. Of the allocated memory 4.66 GiB is allocated by PyTorch, and 784.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTreinando FFJORD em MNIST completo...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mtrain_ffjord\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mffjord\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Começar com 50, pode aumentar\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlambda_ke\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Regularização de energia cinética\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\n\u001b[32m     30\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m train_time = time.time() - start_time\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTempo de treinamento: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_time\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[32m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m minutos\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projetos/flow/notebooks/../src/utils/training.py:240\u001b[39m, in \u001b[36mtrain_ffjord\u001b[39m\u001b[34m(model, dataloader, optimizer, device, n_epochs, lambda_ke, warmup_epochs)\u001b[39m\n\u001b[32m    237\u001b[39m optimizer.zero_grad()\n\u001b[32m    239\u001b[39m \u001b[38;5;66;03m# Calculate log-likelihood\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m log_prob = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m nll = -log_prob.mean()\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# Optional: Kinetic energy regularization\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# KE = 0.5 * ||f(x, t)||^2\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projetos/flow/notebooks/../src/models/ffjord.py:176\u001b[39m, in \u001b[36mFFJORD.log_prob\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    173\u001b[39m     x = x.clone().requires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# Transform x -> z\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m z, log_det = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# log p(x) = log p(z) + log |det(∂z/∂x)|\u001b[39;00m\n\u001b[32m    179\u001b[39m log_prob_z = \u001b[38;5;28mself\u001b[39m.base_dist.log_prob(z)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projetos/flow/notebooks/../src/models/ffjord.py:145\u001b[39m, in \u001b[36mFFJORD.forward\u001b[39m\u001b[34m(self, x, t_span, reverse)\u001b[39m\n\u001b[32m    142\u001b[39m state_init = torch.cat([x, log_det_init], dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    144\u001b[39m \u001b[38;5;66;03m# Integrate augmented ODE\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m state_t = \u001b[43modeint_adjoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_augmented_dynamics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mt_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdopri5\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43matol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43madjoint_params\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# Final state\u001b[39;00m\n\u001b[32m    156\u001b[39m state_final = state_t[-\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# (batch, features + 1)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torchdiffeq/_impl/adjoint.py:206\u001b[39m, in \u001b[36modeint_adjoint\u001b[39m\u001b[34m(func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol, adjoint_method, adjoint_options, adjoint_params)\u001b[39m\n\u001b[32m    203\u001b[39m state_norm = options[\u001b[33m\"\u001b[39m\u001b[33mnorm\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    204\u001b[39m handle_adjoint_norm_(adjoint_options, shapes, state_norm)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m ans = \u001b[43mOdeintAdjointMethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_rtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_atol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m                                \u001b[49m\u001b[43madjoint_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43madjoint_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    210\u001b[39m     solution = ans\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/autograd/function.py:581\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    579\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    580\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    584\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    586\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    587\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    588\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    589\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torchdiffeq/_impl/adjoint.py:24\u001b[39m, in \u001b[36mOdeintAdjointMethod.forward\u001b[39m\u001b[34m(ctx, shapes, func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol, adjoint_method, adjoint_options, t_requires_grad, *adjoint_params)\u001b[39m\n\u001b[32m     21\u001b[39m ctx.event_mode = event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     ans = \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m=\u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevent_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     27\u001b[39m         y = ans\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torchdiffeq/_impl/odeint.py:80\u001b[39m, in \u001b[36modeint\u001b[39m\u001b[34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[39m\n\u001b[32m     77\u001b[39m solver = SOLVERS[method](func=func, y0=y0, rtol=rtol, atol=atol, **options)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     solution = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     82\u001b[39m     event_t, solution = solver.integrate_until_event(t[\u001b[32m0\u001b[39m], event_fn)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torchdiffeq/_impl/solvers.py:32\u001b[39m, in \u001b[36mAdaptiveStepsizeODESolver.integrate\u001b[39m\u001b[34m(self, t)\u001b[39m\n\u001b[32m     30\u001b[39m solution[\u001b[32m0\u001b[39m] = \u001b[38;5;28mself\u001b[39m.y0\n\u001b[32m     31\u001b[39m t = t.to(\u001b[38;5;28mself\u001b[39m.dtype)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_before_integrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[32m     34\u001b[39m     solution[i] = \u001b[38;5;28mself\u001b[39m._advance(t[i])\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:213\u001b[39m, in \u001b[36mRKAdaptiveStepsizeODESolver._before_integrate\u001b[39m\u001b[34m(self, t)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_before_integrate\u001b[39m(\u001b[38;5;28mself\u001b[39m, t):\n\u001b[32m    212\u001b[39m     t0 = t[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     f0 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.first_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    215\u001b[39m         first_step = _select_initial_step(\u001b[38;5;28mself\u001b[39m.func, t[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.y0, \u001b[38;5;28mself\u001b[39m.order - \u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.rtol, \u001b[38;5;28mself\u001b[39m.atol,\n\u001b[32m    216\u001b[39m                                           \u001b[38;5;28mself\u001b[39m.norm, f0=f0)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:197\u001b[39m, in \u001b[36m_PerturbFunc.forward\u001b[39m\u001b[34m(self, t, y, perturb)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    195\u001b[39m     \u001b[38;5;66;03m# Do nothing.\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:197\u001b[39m, in \u001b[36m_PerturbFunc.forward\u001b[39m\u001b[34m(self, t, y, perturb)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    195\u001b[39m     \u001b[38;5;66;03m# Do nothing.\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projetos/flow/notebooks/../src/models/ffjord.py:81\u001b[39m, in \u001b[36mFFJORD._augmented_dynamics\u001b[39m\u001b[34m(self, t, state)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Compute trace of the Jacobian using Hutchinson estimator\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# Wrap in enable_grad to ensure gradient computation works properly\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     trace = \u001b[43mdivergence_hutchinson\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistribution\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistribution\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch,)\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# d(log_det)/dt = -trace (note the sign!)\u001b[39;00m\n\u001b[32m     89\u001b[39m dlogdet_dt = -trace.unsqueeze(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (batch, 1)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projetos/flow/notebooks/../src/utils/trace.py:88\u001b[39m, in \u001b[36mdivergence_hutchinson\u001b[39m\u001b[34m(f, x, num_samples, distribution)\u001b[39m\n\u001b[32m     85\u001b[39m     x = x.requires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Compute f(x)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m f_x = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch, dim)\u001b[39;00m\n\u001b[32m     90\u001b[39m trace_estimates = []\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples):\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# Sample noise vector\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projetos/flow/notebooks/../src/models/ffjord.py:82\u001b[39m, in \u001b[36mFFJORD._augmented_dynamics.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Compute trace of the Jacobian using Hutchinson estimator\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# Wrap in enable_grad to ensure gradient computation works properly\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m     81\u001b[39m     trace = divergence_hutchinson(\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     83\u001b[39m         x,\n\u001b[32m     84\u001b[39m         num_samples=\u001b[38;5;28mself\u001b[39m.num_samples,\n\u001b[32m     85\u001b[39m         distribution=\u001b[38;5;28mself\u001b[39m.distribution\n\u001b[32m     86\u001b[39m     )  \u001b[38;5;66;03m# (batch,)\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# d(log_det)/dt = -trace (note the sign!)\u001b[39;00m\n\u001b[32m     89\u001b[39m dlogdet_dt = -trace.unsqueeze(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (batch, 1)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projetos/flow/notebooks/../src/models/vector_field.py:272\u001b[39m, in \u001b[36mVectorFieldMNIST.forward\u001b[39m\u001b[34m(self, t, x)\u001b[39m\n\u001b[32m    268\u001b[39m x_img = x.view(batch_size, \u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.image_size, \u001b[38;5;28mself\u001b[39m.image_size)\n\u001b[32m    270\u001b[39m \u001b[38;5;66;03m# Pass through CNN\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[38;5;66;03m# (batch, channels[-1], 28, 28)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m cnn_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;66;03m# (batch, channels[-1]*28*28)\u001b[39;00m\n\u001b[32m    274\u001b[39m cnn_features_flat = cnn_features.view(batch_size, -\u001b[32m1\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/normalization.py:325\u001b[39m, in \u001b[36mGroupNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/functional.py:2956\u001b[39m, in \u001b[36mgroup_norm\u001b[39m\u001b[34m(input, num_groups, weight, bias, eps)\u001b[39m\n\u001b[32m   2949\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2950\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected at least 2 dimensions for input tensor but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2951\u001b[39m     )\n\u001b[32m   2952\u001b[39m _verify_batch_size(\n\u001b[32m   2953\u001b[39m     [\u001b[38;5;28minput\u001b[39m.size(\u001b[32m0\u001b[39m) * \u001b[38;5;28minput\u001b[39m.size(\u001b[32m1\u001b[39m) // num_groups, num_groups]\n\u001b[32m   2954\u001b[39m     + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m.size()[\u001b[32m2\u001b[39m:])\n\u001b[32m   2955\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2956\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2957\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\n\u001b[32m   2958\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 5.91 GiB of which 314.25 MiB is free. Including non-PyTorch memory, this process has 5.56 GiB memory in use. Of the allocated memory 4.66 GiB is allocated by PyTorch, and 784.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# Criar Vector Field\n",
        "vf = VectorFieldMNIST(\n",
        "    features=784,\n",
        "    channels=[512, 512, 512],\n",
        "    time_embed_dim=32\n",
        ").to(device)\n",
        "\n",
        "# Criar FFJORD\n",
        "ffjord = FFJORD(\n",
        "    vector_field=vf,\n",
        "    num_samples=1,\n",
        "    distribution='rademacher'\n",
        ").to(device)\n",
        "\n",
        "# Otimizador com learning rate menor\n",
        "optimizer = optim.Adam(ffjord.parameters(), lr=1e-4)\n",
        "\n",
        "# Treinar FFJORD\n",
        "print(\"Treinando FFJORD em MNIST completo...\")\n",
        "start_time = time.time()\n",
        "\n",
        "train_ffjord(\n",
        "    ffjord,\n",
        "    train_loader,\n",
        "    optimizer,\n",
        "    device,\n",
        "    n_epochs=50,  # Começar com 50, pode aumentar\n",
        "    lambda_ke=0.01,  # Regularização de energia cinética\n",
        "    warmup_epochs=5\n",
        ")\n",
        "\n",
        "train_time = time.time() - start_time\n",
        "print(f\"\\nTempo de treinamento: {train_time / 60:.2f} minutos\")\n",
        "\n",
        "# Salvar checkpoint\n",
        "checkpoint_path = os.path.join(CHECKPOINTS_DIR, f'03__{DATASET_NAME}_ffjord.pt')\n",
        "torch.save(ffjord.state_dict(), checkpoint_path)\n",
        "print(f\"Checkpoint saved to: {checkpoint_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Avaliar Modelo\n",
        "\n",
        "Calcular log-likelihood e bits per dimension no conjunto de teste.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bits_per_dim(log_prob, n_dims):\n",
        "    \"\"\"Calcular bits per dimension.\"\"\"\n",
        "    return -log_prob / (n_dims * np.log(2))\n",
        "\n",
        "\n",
        "# Carregar modelo do checkpoint\n",
        "checkpoint_path = os.path.join(CHECKPOINTS_DIR, f'03__{DATASET_NAME}_ffjord.pt')\n",
        "vf = VectorFieldMNIST(\n",
        "    features=784,\n",
        "    channels=[512, 512, 512],\n",
        "    time_embed_dim=32\n",
        ").to(device)\n",
        "ffjord = FFJORD(\n",
        "    vector_field=vf,\n",
        "    num_samples=1,\n",
        "    distribution='rademacher'\n",
        ").to(device)\n",
        "ffjord.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "ffjord.eval()\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "test_log_probs = []\n",
        "test_bpd = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        if isinstance(batch, (list, tuple)):\n",
        "            x = batch[0].to(device)\n",
        "        else:\n",
        "            x = batch.to(device)\n",
        "\n",
        "        log_prob = ffjord.log_prob(x)\n",
        "        bpd = bits_per_dim(log_prob, n_dims=784)\n",
        "\n",
        "        test_log_probs.append(log_prob.cpu().numpy())\n",
        "        test_bpd.append(bpd.cpu().numpy())\n",
        "\n",
        "test_log_probs = np.concatenate(test_log_probs)\n",
        "test_bpd = np.concatenate(test_bpd)\n",
        "\n",
        "print(f\"Test Log-likelihood: {test_log_probs.mean():.4f} ± {test_log_probs.std():.4f}\")\n",
        "print(f\"Test Bits per Dimension: {test_bpd.mean():.4f} ± {test_bpd.std():.4f}\")\n",
        "\n",
        "# Histograma de bits per dimension\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(test_bpd, bins=50, alpha=0.7, edgecolor='black')\n",
        "plt.axvline(test_bpd.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {test_bpd.mean():.4f}')\n",
        "plt.xlabel('Bits per Dimension', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.title('Distribution of Bits per Dimension (Test Set)', fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIGURES_DIR, f'03_{DATASET_NAME}_ffjord_bits_per_dim.png'), dpi=300, bbox_inches='tight')\n",
        "print(f\"Figure saved to: {os.path.join(FIGURES_DIR, f'03_{DATASET_NAME}_ffjord_bits_per_dim.png')}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Gerar Amostras\n",
        "\n",
        "Gerar novas amostras a partir do modelo treinado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar modelo do checkpoint\n",
        "checkpoint_path = os.path.join(CHECKPOINTS_DIR, f'03__{DATASET_NAME}_ffjord.pt')\n",
        "vf = VectorFieldMNIST(\n",
        "    features=784,\n",
        "    channels=[512, 512, 512],\n",
        "    time_embed_dim=32\n",
        ").to(device)\n",
        "ffjord = FFJORD(\n",
        "    vector_field=vf,\n",
        "    num_samples=1,\n",
        "    distribution='rademacher'\n",
        ").to(device)\n",
        "ffjord.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "ffjord.eval()\n",
        "\n",
        "# Gerar amostras\n",
        "print(\"Gerando amostras...\")\n",
        "start_time = time.time()\n",
        "samples = ffjord.sample(64)  # Gerar 64 amostras\n",
        "sample_time = time.time() - start_time\n",
        "\n",
        "print(f\"Tempo de geração (64 amostras): {sample_time:.2f} segundos\")\n",
        "print(f\"Tempo por amostra: {sample_time/64:.3f} segundos\")\n",
        "\n",
        "# Converter de logit space para [0, 1] para visualização\n",
        "samples_vis = torch.sigmoid(samples).cpu().numpy()\n",
        "\n",
        "# Visualizar amostras\n",
        "fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n",
        "for i in range(64):\n",
        "    row, col = i // 8, i % 8\n",
        "    img = samples_vis[i].reshape(28, 28)\n",
        "    axes[row, col].imshow(img, cmap='gray')\n",
        "    axes[row, col].axis('off')\n",
        "plt.suptitle('FFJORD Generated Samples', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIGURES_DIR, f'03_{DATASET_NAME}_ffjord_generated_samples.png'), dpi=300, bbox_inches='tight')\n",
        "print(f\"Figure saved to: {os.path.join(FIGURES_DIR, f'03_{DATASET_NAME}_ffjord_generated_samples.png')}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Análise de NFEs (Number of Function Evaluations)\n",
        "\n",
        "Analisar quantas avaliações da função são necessárias durante a integração ODE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar modelo do checkpoint\n",
        "checkpoint_path = os.path.join(CHECKPOINTS_DIR, f'03__{DATASET_NAME}_ffjord.pt')\n",
        "vf = VectorFieldMNIST(\n",
        "    features=784,\n",
        "    channels=[512, 512, 512],\n",
        "    time_embed_dim=32\n",
        ").to(device)\n",
        "ffjord = FFJORD(\n",
        "    vector_field=vf,\n",
        "    num_samples=1,\n",
        "    distribution='rademacher'\n",
        ").to(device)\n",
        "ffjord.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "ffjord.eval()\n",
        "\n",
        "# Contar NFEs durante forward pass\n",
        "from src.utils.training import CountingVectorField2D\n",
        "\n",
        "\n",
        "def count_nfe_ffjord(model, x, reverse=False):\n",
        "    \"\"\"Contar NFEs para FFJORD.\"\"\"\n",
        "    counting_vf = CountingVectorField2D(model.vf)\n",
        "    original_vf = model.vf\n",
        "    model.vf = counting_vf\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _, _ = model.forward(x, reverse=reverse)\n",
        "\n",
        "    nfe = counting_vf.nfe\n",
        "    model.vf = original_vf\n",
        "    return nfe\n",
        "\n",
        "\n",
        "# Testar em um batch pequeno\n",
        "test_batch = next(iter(test_loader))\n",
        "if isinstance(test_batch, (list, tuple)):\n",
        "    x_test = test_batch[0][:10].to(device)\n",
        "else:\n",
        "    x_test = test_batch[:10].to(device)\n",
        "\n",
        "nfe_forward = count_nfe_ffjord(ffjord, x_test, reverse=False)\n",
        "nfe_reverse = count_nfe_ffjord(ffjord, x_test, reverse=True)\n",
        "\n",
        "print(f\"NFEs (forward, x -> z): {nfe_forward}\")\n",
        "print(f\"NFEs (reverse, z -> x): {nfe_reverse}\")\n",
        "print(\n",
        "    \"NFEs médio por amostra: \"\n",
        "    f\"{(nfe_forward + nfe_reverse) / 2 / len(x_test):.1f}\"\n",
        ")\n",
        "\n",
        "# Comparar com diferentes tolerâncias\n",
        "print(\"\\n=== Comparação de Tolerâncias ===\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Comparação com RealNVP (Opcional)\n",
        "\n",
        "Comparar FFJORD com RealNVP baseline para entender trade-offs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar e treinar RealNVP para comparação\n",
        "print(\"Treinando RealNVP para comparação...\")\n",
        "realnvp = RealNVP(\n",
        "    features=784,\n",
        "    transforms=4,\n",
        "    hidden_features=[512, 512]\n",
        ").to(device)\n",
        "\n",
        "optimizer_rnvp = optim.Adam(realnvp.parameters(), lr=1e-4)\n",
        "\n",
        "start_time = time.time()\n",
        "train_realnvp(realnvp, train_loader, optimizer_rnvp, device, n_epochs=50)\n",
        "train_time_rnvp = time.time() - start_time\n",
        "print(f\"Tempo de treinamento RealNVP: {train_time_rnvp/60:.2f} minutos\")\n",
        "\n",
        "# Salvar checkpoint\n",
        "checkpoint_path = os.path.join(CHECKPOINTS_DIR, f'03__{DATASET_NAME}_realnvp.pt')\n",
        "torch.save(realnvp.state_dict(), checkpoint_path)\n",
        "print(f\"Checkpoint saved to: {checkpoint_path}\")\n",
        "\n",
        "# Avaliar RealNVP\n",
        "realnvp.eval()\n",
        "test_log_probs_rnvp = []\n",
        "test_bpd_rnvp = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        if isinstance(batch, (list, tuple)):\n",
        "            x = batch[0].to(device)\n",
        "        else:\n",
        "            x = batch.to(device)\n",
        "\n",
        "        dist = realnvp(None)\n",
        "        log_prob = dist.log_prob(x)\n",
        "        bpd = bits_per_dim(log_prob, n_dims=784)\n",
        "\n",
        "        test_log_probs_rnvp.append(log_prob.cpu().numpy())\n",
        "        test_bpd_rnvp.append(bpd.cpu().numpy())\n",
        "\n",
        "test_log_probs_rnvp = np.concatenate(test_log_probs_rnvp)\n",
        "test_bpd_rnvp = np.concatenate(test_bpd_rnvp)\n",
        "\n",
        "print(\"\\n=== Comparação ===\")\n",
        "print(f\"FFJORD - Test BPD: {test_bpd.mean():.4f} ± {test_bpd.std():.4f}\")\n",
        "print(\n",
        "    f\"RealNVP - Test BPD: {test_bpd_rnvp.mean():.4f} ± \"\n",
        "    f\"{test_bpd_rnvp.std():.4f}\"\n",
        ")\n",
        "print(f\"\\nFFJORD - Train time: {train_time/60:.2f} min\")\n",
        "print(f\"RealNVP - Train time: {train_time_rnvp/60:.2f} min\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar modelos dos checkpoints\n",
        "# FFJORD\n",
        "checkpoint_path_ffjord = os.path.join(CHECKPOINTS_DIR, f'03__{DATASET_NAME}_ffjord.pt')\n",
        "vf = VectorFieldMNIST(\n",
        "    features=784,\n",
        "    channels=[512, 512, 512],\n",
        "    time_embed_dim=32\n",
        ").to(device)\n",
        "ffjord = FFJORD(\n",
        "    vector_field=vf,\n",
        "    num_samples=1,\n",
        "    distribution='rademacher'\n",
        ").to(device)\n",
        "ffjord.load_state_dict(torch.load(checkpoint_path_ffjord, map_location=device))\n",
        "ffjord.eval()\n",
        "\n",
        "# RealNVP\n",
        "checkpoint_path_rnvp = os.path.join(CHECKPOINTS_DIR, f'03__{DATASET_NAME}_realnvp.pt')\n",
        "realnvp = RealNVP(\n",
        "    features=784,\n",
        "    transforms=4,\n",
        "    hidden_features=[512, 512]\n",
        ").to(device)\n",
        "realnvp.load_state_dict(torch.load(checkpoint_path_rnvp, map_location=device))\n",
        "realnvp.eval()\n",
        "\n",
        "# Gerar amostras do FFJORD\n",
        "start_time = time.time()\n",
        "samples_ffjord = ffjord.sample(64)\n",
        "sample_time_ffjord = time.time() - start_time\n",
        "samples_vis = torch.sigmoid(samples_ffjord).cpu().numpy()\n",
        "\n",
        "# Gerar amostras do RealNVP\n",
        "start_time = time.time()\n",
        "samples_rnvp = realnvp(None).sample((64,))\n",
        "sample_time_rnvp = time.time() - start_time\n",
        "\n",
        "samples_rnvp_vis = torch.sigmoid(samples_rnvp).cpu().numpy()\n",
        "\n",
        "# Visualizar comparação\n",
        "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
        "for i in range(8):\n",
        "    # FFJORD\n",
        "    img_ffjord = samples_vis[i].reshape(28, 28)\n",
        "    axes[0, i].imshow(img_ffjord, cmap='gray')\n",
        "    axes[0, i].axis('off')\n",
        "    if i == 0:\n",
        "        axes[0, i].set_ylabel('FFJORD', fontsize=12)\n",
        "\n",
        "    # RealNVP\n",
        "    img_rnvp = samples_rnvp_vis[i].reshape(28, 28)\n",
        "    axes[1, i].imshow(img_rnvp, cmap='gray')\n",
        "    axes[1, i].axis('off')\n",
        "    if i == 0:\n",
        "        axes[1, i].set_ylabel('RealNVP', fontsize=12)\n",
        "\n",
        "plt.suptitle('Sample Comparison: FFJORD vs RealNVP', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIGURES_DIR, f'03_{DATASET_NAME}_comparison_ffjord_realnvp.png'), dpi=300, bbox_inches='tight')\n",
        "print(f\"Figure saved to: {os.path.join(FIGURES_DIR, f'03_{DATASET_NAME}_comparison_ffjord_realnvp.png')}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Análise e Conclusões\n",
        "\n",
        "### Trade-offs Computacionais\n",
        "\n",
        "**FFJORD:**\n",
        "- ✅ Escalável a dimensões altas (O(d) com Hutchinson)\n",
        "- ✅ Expressivo (transformações contínuas)\n",
        "- ❌ Mais lento que discrete flows (integração ODE)\n",
        "- ❌ Requer mais memória (adjoint method)\n",
        "\n",
        "**RealNVP:**\n",
        "- ✅ Rápido (forward pass direto)\n",
        "- ✅ Eficiente em memória\n",
        "- ❌ Menos expressivo (transformações discretas)\n",
        "- ❌ Requer arquitetura cuidadosa (coupling layers)\n",
        "\n",
        "### Por que Hutchinson é essencial?\n",
        "\n",
        "- **Trace exato**: O(d²) = O(784²) = O(614,656) operações\n",
        "- **Hutchinson**: O(d) = O(784) operações\n",
        "- **Speedup**: ~784x mais rápido!\n",
        "\n",
        "### Preparação para Flow Matching\n",
        "\n",
        "FFJORD é um precursor conceitual para Flow Matching:\n",
        "- Ambos usam ODEs contínuas\n",
        "- Ambos aprendem vector fields\n",
        "- Flow Matching melhora: treinamento mais estável, sem necessidade de trace\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "flow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
