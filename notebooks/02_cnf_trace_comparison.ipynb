{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 2: CNF com Trace Exato\n",
        "\n",
        "Este notebook implementa CNF completo com cálculo de log-likelihood via change of variables.\n",
        "\n",
        "## Objetivos:\n",
        "1. Implementar divergence_exact e CNF\n",
        "2. Treinar em dados 2D e MNIST reduzido\n",
        "3. Comparar com Real NVP baseline\n",
        "4. Analisar escalabilidade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "import time\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from src.models.cnf import CNF\n",
        "from src.models.vector_field import VectorField\n",
        "from src.utils.datasets import Synthetic2D, MNISTReduced, get_dataloader\n",
        "from src.utils.training import train_cnf\n",
        "from src.utils.visualization import plot_data_distribution\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. CNF em Dados 2D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar dataset 2D\n",
        "dataset_2d = Synthetic2D(n_samples=5000, noise=0.05, dataset_type='moons')\n",
        "dataloader_2d = get_dataloader(dataset_2d, batch_size=128, shuffle=True)\n",
        "\n",
        "# Visualizar\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
        "plot_data_distribution(\n",
        "    dataset_2d.data,\n",
        "    labels=dataset_2d.labels,\n",
        "    ax=ax,\n",
        "    title=\"Dataset: Two Moons\"\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Criar e treinar CNF\n",
        "vf_2d = VectorField(features=2, hidden_dims=[64, 64], time_embed_dim=16)\n",
        "cnf_2d = CNF(vf_2d).to(device)\n",
        "optimizer_2d = optim.Adam(cnf_2d.parameters(), lr=1e-3)\n",
        "\n",
        "print(\"Treinando CNF em dados 2D...\")\n",
        "train_cnf(cnf_2d, dataloader_2d, optimizer_2d, device, num_epochs=5)\n",
        "\n",
        "# Avaliar log-likelihood\n",
        "cnf_2d.eval()\n",
        "with torch.no_grad():\n",
        "    test_data = dataset_2d.data[:1000].to(device)\n",
        "    log_probs = cnf_2d.log_prob(test_data)\n",
        "    print(f\"Log-likelihood médio: {log_probs.mean().item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. CNF em MNIST Reduzido\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Carregando MNIST reduzido...\n",
            "Treinando CNF em MNIST reduzido...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5:  36%|███▌      | 167/469 [05:31<09:59,  1.98s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTreinando CNF em MNIST reduzido...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mtrain_cnf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnf_mnist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_mnist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_mnist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m train_time = time.time() - start_time\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTempo de treinamento: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m segundos\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projetos/flow/notebooks/../src/utils/training.py:165\u001b[39m, in \u001b[36mtrain_cnf\u001b[39m\u001b[34m(model, dataloader, optimizer, device, num_epochs)\u001b[39m\n\u001b[32m    162\u001b[39m with torch.no_grad():\n\u001b[32m    163\u001b[39m     _, _ = model(x, t_span)\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m # Get count\n\u001b[32m    166\u001b[39m nfe_count = counting_vf.nfe\n\u001b[32m    168\u001b[39m # Restore original vector field\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projetos/flow/notebooks/../src/models/cnf.py:179\u001b[39m, in \u001b[36mCNF.log_prob\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    176\u001b[39m     x = x.clone().requires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# Transform x -> z\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m z, log_det = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# log p(x) = log p(z) + log |det(∂z/∂x)|\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# Since we integrate from x to z, log_det is log |det(∂z/∂x)|\u001b[39;00m\n\u001b[32m    183\u001b[39m base_dist = \u001b[38;5;28mself\u001b[39m._get_base_dist(z.device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projetos/flow/notebooks/../src/models/cnf.py:149\u001b[39m, in \u001b[36mCNF.forward\u001b[39m\u001b[34m(self, x, reverse)\u001b[39m\n\u001b[32m    146\u001b[39m state_init = torch.cat([x, log_det_init], dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    148\u001b[39m \u001b[38;5;66;03m# Regular odeint handles both input and parameter gradients\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m state_t = \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_augmented_dynamics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mt_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43matol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43matol\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# Final state\u001b[39;00m\n\u001b[32m    159\u001b[39m state_final = state_t[-\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# (batch, features + 1)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torchdiffeq/_impl/odeint.py:80\u001b[39m, in \u001b[36modeint\u001b[39m\u001b[34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[39m\n\u001b[32m     77\u001b[39m solver = SOLVERS[method](func=func, y0=y0, rtol=rtol, atol=atol, **options)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     solution = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     82\u001b[39m     event_t, solution = solver.integrate_until_event(t[\u001b[32m0\u001b[39m], event_fn)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torchdiffeq/_impl/solvers.py:34\u001b[39m, in \u001b[36mAdaptiveStepsizeODESolver.integrate\u001b[39m\u001b[34m(self, t)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mself\u001b[39m._before_integrate(t)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     solution[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_advance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:246\u001b[39m, in \u001b[36mRKAdaptiveStepsizeODESolver._advance\u001b[39m\u001b[34m(self, next_t)\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m next_t > \u001b[38;5;28mself\u001b[39m.rk_state.t1:\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m n_steps < \u001b[38;5;28mself\u001b[39m.max_num_steps, \u001b[33m'\u001b[39m\u001b[33mmax_num_steps exceeded (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m>=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m'\u001b[39m.format(n_steps, \u001b[38;5;28mself\u001b[39m.max_num_steps)\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[38;5;28mself\u001b[39m.rk_state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_adaptive_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrk_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m     n_steps += \u001b[32m1\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _interp_evaluate(\u001b[38;5;28mself\u001b[39m.rk_state.interp_coeff, \u001b[38;5;28mself\u001b[39m.rk_state.t0, \u001b[38;5;28mself\u001b[39m.rk_state.t1, next_t)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:311\u001b[39m, in \u001b[36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[39m\u001b[34m(self, rk_state)\u001b[39m\n\u001b[32m    306\u001b[39m         dt = t1 - t0\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Must be arranged as doing all the step_t handling, then all the jump_t handling, in case we\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# trigger both. (i.e. interleaving them would be wrong.)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m y1, f1, y1_error, k = \u001b[43m_runge_kutta_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtableau\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtableau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;66;03m# dtypes:\u001b[39;00m\n\u001b[32m    313\u001b[39m \u001b[38;5;66;03m# y1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[32m    314\u001b[39m \u001b[38;5;66;03m# f1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m \u001b[38;5;66;03m#                     Error Ratio                      #\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[38;5;66;03m########################################################\u001b[39;00m\n\u001b[32m    321\u001b[39m error_ratio = _compute_error_ratio(y1_error, \u001b[38;5;28mself\u001b[39m.rtol, \u001b[38;5;28mself\u001b[39m.atol, y0, y1, \u001b[38;5;28mself\u001b[39m.norm)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:78\u001b[39m, in \u001b[36m_runge_kutta_step\u001b[39m\u001b[34m(func, y0, f0, t0, dt, t1, tableau)\u001b[39m\n\u001b[32m     76\u001b[39m         perturb = Perturb.NONE\n\u001b[32m     77\u001b[39m     yi = y0 + torch.sum(k[..., :i + \u001b[32m1\u001b[39m] * (beta_i * dt), dim=-\u001b[32m1\u001b[39m).view_as(f0)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     f = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperturb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     k = _UncheckedAssign.apply(k, f, (..., i + \u001b[32m1\u001b[39m))\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (tableau.c_sol[-\u001b[32m1\u001b[39m] == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (tableau.c_sol[:-\u001b[32m1\u001b[39m] == tableau.beta[-\u001b[32m1\u001b[39m]).all()):\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# This property (true for Dormand-Prince) lets us save a few FLOPs.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:197\u001b[39m, in \u001b[36m_PerturbFunc.forward\u001b[39m\u001b[34m(self, t, y, perturb)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    195\u001b[39m     \u001b[38;5;66;03m# Do nothing.\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projetos/flow/notebooks/../src/models/cnf.py:102\u001b[39m, in \u001b[36mCNF._augmented_dynamics\u001b[39m\u001b[34m(self, t, state)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    101\u001b[39m     dx_dt = \u001b[38;5;28mself\u001b[39m.vf(t, x)\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     trace = \u001b[43mdivergence_exact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m dlogdet_dt = -trace.unsqueeze(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (batch, 1)\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat([dx_dt, dlogdet_dt], dim=-\u001b[32m1\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projetos/flow/notebooks/../src/utils/trace.py:34\u001b[39m, in \u001b[36mdivergence_exact\u001b[39m\u001b[34m(f, x)\u001b[39m\n\u001b[32m     30\u001b[39m trace = torch.zeros(batch_size, device=x.device, dtype=x.dtype)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dim):\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# Compute ∂f[:, i]/∂x\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     df_i = \u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (batch, dim)\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Sum only the diagonal: ∂f_i/∂x_i\u001b[39;00m\n\u001b[32m     42\u001b[39m     trace += df_i[:, i]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/autograd/__init__.py:503\u001b[39m, in \u001b[36mgrad\u001b[39m\u001b[34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[39m\n\u001b[32m    499\u001b[39m     result = _vmap_internals._vmap(vjp, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, allow_none_pass_through=\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[32m    500\u001b[39m         grad_outputs_\n\u001b[32m    501\u001b[39m     )\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m     result = \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m    514\u001b[39m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[32m    515\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[32m    516\u001b[39m     ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/flow/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Criar dataset MNIST reduzido (100 dimensões)\n",
        "print(\"Carregando MNIST reduzido...\")\n",
        "dataset_mnist = MNISTReduced(train=True, n_components=100)\n",
        "dataloader_mnist = get_dataloader(dataset_mnist, batch_size=128, shuffle=True)\n",
        "\n",
        "# Criar e treinar CNF\n",
        "vf_mnist = VectorField(features=100, hidden_dims=[128, 128], time_embed_dim=32)\n",
        "cnf_mnist = CNF(vf_mnist).to(device)\n",
        "optimizer_mnist = optim.Adam(cnf_mnist.parameters(), lr=1e-3)\n",
        "\n",
        "print(\"Treinando CNF em MNIST reduzido...\")\n",
        "start_time = time.time()\n",
        "train_cnf(cnf_mnist, dataloader_mnist, optimizer_mnist, device, num_epochs=5)\n",
        "train_time = time.time() - start_time\n",
        "print(f\"Tempo de treinamento: {train_time:.2f} segundos\")\n",
        "\n",
        "# Avaliar log-likelihood\n",
        "cnf_mnist.eval()\n",
        "with torch.no_grad():\n",
        "    test_data = dataset_mnist.data[:1000].to(device)\n",
        "    log_probs = cnf_mnist.log_prob(test_data)\n",
        "    print(f\"Log-likelihood médio: {log_probs.mean().item():.4f}\")\n",
        "\n",
        "# Tempo de sampling\n",
        "start_time = time.time()\n",
        "samples = cnf_mnist.sample(1000)\n",
        "sample_time = time.time() - start_time\n",
        "print(f\"Tempo de sampling (1000 amostras): {sample_time:.2f} segundos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Análise de Escalabilidade\n",
        "\n",
        "**Por que trace exato não escala para MNIST completo (784 dim)?**\n",
        "\n",
        "- Custo computacional: O(d²) onde d é a dimensão\n",
        "- Para d=784: precisamos de 784 backward passes\n",
        "- Cada backward é O(784) → Total O(784²) = O(614,656)\n",
        "- Isso é muito lento para treinamento prático!\n",
        "\n",
        "**Solução:** Usar Hutchinson trace estimator (FFJORD) - O(d)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "flow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
