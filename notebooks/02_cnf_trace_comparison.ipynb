{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 2: CNF com Trace Exato\n",
        "\n",
        "Este notebook implementa CNF completo com cálculo de log-likelihood via change of variables.\n",
        "\n",
        "## Objetivos:\n",
        "1. Implementar divergence_exact e CNF\n",
        "2. Treinar em dados 2D e MNIST reduzido\n",
        "3. Comparar com Real NVP baseline\n",
        "4. Analisar escalabilidade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from src.models.vector_field import VectorField\n",
        "from src.models.cnf import CNF\n",
        "from src.utils.datasets import Synthetic2D, MNISTReduced, get_dataloader\n",
        "from src.utils.training import train_cnf\n",
        "from src.utils.visualization import plot_data_distribution\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. CNF em Dados 2D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar dataset 2D\n",
        "dataset_2d = Synthetic2D(n_samples=5000, noise=0.05, dataset_type='moons')\n",
        "dataloader_2d = get_dataloader(dataset_2d, batch_size=128, shuffle=True)\n",
        "\n",
        "# Criar e treinar CNF\n",
        "vf_2d = VectorField(features=2, hidden_dims=[64, 64], time_embed_dim=16)\n",
        "cnf_2d = CNF(vf_2d).to(device)\n",
        "optimizer_2d = optim.Adam(cnf_2d.parameters(), lr=1e-3)\n",
        "\n",
        "print(\"Treinando CNF em dados 2D...\")\n",
        "train_cnf(cnf_2d, dataloader_2d, optimizer_2d, device, num_epochs=50)\n",
        "\n",
        "# Avaliar log-likelihood\n",
        "cnf_2d.eval()\n",
        "with torch.no_grad():\n",
        "    test_data = dataset_2d.data[:1000].to(device)\n",
        "    log_probs = cnf_2d.log_prob(test_data)\n",
        "    print(f\"Log-likelihood médio: {log_probs.mean().item():.4f}\")\n",
        "\n",
        "# Gerar amostras\n",
        "samples = cnf_2d.sample(1000)\n",
        "samples_np = samples.cpu().numpy()\n",
        "\n",
        "# Visualizar\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "plot_data_distribution(dataset_2d.data, ax=axes[0], title=\"Dados Originais\")\n",
        "axes[1].scatter(samples_np[:, 0], samples_np[:, 1], alpha=0.5, s=10)\n",
        "axes[1].set_title(\"Amostras Geradas\")\n",
        "axes[1].set_xlabel('x1')\n",
        "axes[1].set_ylabel('x2')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].axis('equal')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. CNF em MNIST Reduzido\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar dataset MNIST reduzido (100 dimensões)\n",
        "print(\"Carregando MNIST reduzido...\")\n",
        "dataset_mnist = MNISTReduced(train=True, n_components=100)\n",
        "dataloader_mnist = get_dataloader(dataset_mnist, batch_size=128, shuffle=True)\n",
        "\n",
        "# Criar e treinar CNF\n",
        "vf_mnist = VectorField(features=100, hidden_dims=[128, 128], time_embed_dim=32)\n",
        "cnf_mnist = CNF(vf_mnist).to(device)\n",
        "optimizer_mnist = optim.Adam(cnf_mnist.parameters(), lr=1e-3)\n",
        "\n",
        "print(\"Treinando CNF em MNIST reduzido...\")\n",
        "start_time = time.time()\n",
        "train_cnf(cnf_mnist, dataloader_mnist, optimizer_mnist, device, num_epochs=10)\n",
        "train_time = time.time() - start_time\n",
        "print(f\"Tempo de treinamento: {train_time:.2f} segundos\")\n",
        "\n",
        "# Avaliar log-likelihood\n",
        "cnf_mnist.eval()\n",
        "with torch.no_grad():\n",
        "    test_data = dataset_mnist.data[:1000].to(device)\n",
        "    log_probs = cnf_mnist.log_prob(test_data)\n",
        "    print(f\"Log-likelihood médio: {log_probs.mean().item():.4f}\")\n",
        "\n",
        "# Tempo de sampling\n",
        "start_time = time.time()\n",
        "samples = cnf_mnist.sample(1000)\n",
        "sample_time = time.time() - start_time\n",
        "print(f\"Tempo de sampling (1000 amostras): {sample_time:.2f} segundos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Análise de Escalabilidade\n",
        "\n",
        "**Por que trace exato não escala para MNIST completo (784 dim)?**\n",
        "\n",
        "- Custo computacional: O(d²) onde d é a dimensão\n",
        "- Para d=784: precisamos de 784 backward passes\n",
        "- Cada backward é O(784) → Total O(784²) = O(614,656)\n",
        "- Isso é muito lento para treinamento prático!\n",
        "\n",
        "**Solução:** Usar Hutchinson trace estimator (FFJORD) - O(d)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
